{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.loads(f.read())\n",
    "    \n",
    "    host = credentials[\"host\"]\n",
    "    user = credentials[\"db_user\"]\n",
    "    password = credentials[\"db_pass\"]\n",
    "    db = credentials[\"db_name\"]\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:3306/{db}\")\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM trips_2017 WHERE lineid = \"46A\" AND direction = 1', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace missing actual time departure values with timetable values\n",
    "df.actualtime_dep.fillna(df.plannedtime_dep, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values for actual time arrival as we cannot safely assume these are as per timetable\n",
    "df = df[pd.notnull(df['actualtime_arr'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for trip duration\n",
    "df['trip_duration'] = df['actualtime_arr'] - df['actualtime_dep']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the hour of the day the trip took place\n",
    "df['actualtime_dep_H'] = round(df['actualtime_dep']/3600)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of actual time arrival\n",
    "df['actualtime_arr_H'] = round(df['actualtime_arr']/3600)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average hour of the day of the journey\n",
    "df['avg_H'] = (df['actualtime_dep_H'] + df['actualtime_arr_H']) / 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_H'] = df['avg_H'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating column solely for the dates to correlate with the dates column on the historical weather data table\n",
    "df['time'] = df['timestamp'] + df['avg_H'] * 3600\n",
    "df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing suppressed rows where suppressed=1.0\n",
    "df = df.query('suppressed != 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns from timestamp for further processing\n",
    "df['dayofweek'] = df['timestamp']\n",
    "df['monthofyear'] = df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the unix time to datetime format\n",
    "df.dayofweek = pd.to_datetime(df['dayofweek'], unit='s')\n",
    "df.monthofyear = pd.to_datetime(df['monthofyear'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datetime to name of weekday, and to name of month (in separate columns)\n",
    "df['dayofweek'] = df['dayofweek'].dt.weekday_name\n",
    "df['monthofyear'] = df['monthofyear'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for weekday names and name of month\n",
    "df_dayofweek_dummies = pd.get_dummies(df['dayofweek'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows not in the month of March\n",
    "df = df.query('monthofyear == 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df, df_dayofweek_dummies], axis=1, join_axes=[df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull weather data from database\n",
    "df2 = pd.read_sql_query('SELECT * FROM DarkSky_historical_weather_data WHERE year = 2017', engine)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'clear-day':'clear','clear-night':'clear','partly-cloudy-day':'partly-cloudy','partly-cloudy-night':'partly-cloudy'}\n",
    "df2 = df2.replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'day_of_week': 'dayofweek', 'month': 'monthofyear'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['avg_H', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'temp', 'precip_intensity','trip_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip duration is in seconds, convert to minutes and round to the nearest integer\n",
    "df3['trip_duration'] = round(df3['trip_duration']/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['trip_duration'] = df3['trip_duration'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['temp'] = round(df3['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['temp'] = df3['temp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = df3[['avg_H', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'temp','trip_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "You can see that our dataset has eleven columns. The task is to predict the trip duration (last column) based on the day of the week, the time of the day and the weather conditions (temperature and rain intesity). The next step is to split our dataset into attributes and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data from first four columns to X variable\n",
    "X = df3.iloc[:, 0:10]\n",
    "\n",
    "# Assign data from fifth column to y variable\n",
    "y = df3['trip_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset 70/30\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#examples-using-sklearn-ensemble-randomforestregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is 10 trees; use n_estimators : integer, optional (default=10)\n",
    "# The number of trees in the forest.\n",
    "regr = RandomForestRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# storing the model trained on the full data set to a pickle file\n",
    "pkl_filename = \"RFR_March_2017_46A_1.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(regr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the importance of each feature based on the model\n",
    "pd.DataFrame({'feature': X.columns, 'importance': regr.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(regr.predict([[9, 0, 1, 0, 0, 0, 0, 0, 12, 0.0]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = regr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(pred)\n",
    "predictions.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions['estimated_time'] = round(predictions['estimated_time'])\n",
    "predictions['estimated_time'] = predictions['estimated_time'].astype(int)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y, predictions))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y, predictions))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Training data:\\n\", pd.concat([X_train, y_train], axis=1))\n",
    "print(\"\\nTest data:\\n\", pd.concat([X_test, y_test], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data using the training set\n",
    "#regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the importance of each feature based on the model\n",
    "#pd.DataFrame({'feature': X.columns, 'importance': regr.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rfc_predictions_test = regr.predict(X_test)\n",
    "#df_true_vs_rfc_predicted_test = pd.DataFrame({'ActualClass': y_test, 'PredictedClass': rfc_predictions_test})\n",
    "#df_true_vs_rfc_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('RFR_March_2017_46A_1.pkl','rb') as picklefile:\n",
    "        rfr_ = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate current date and time\n",
    "import datetime as dt\n",
    "day = dt.datetime.today().weekday() # current day of the week 0=Monday\n",
    "hour = (dt.datetime.now().hour)  # current hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold current time\n",
    "df_time = pd.DataFrame({'avg_H': [hour]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame to hold current day of week DOW\n",
    "df_dummies_DOW = pd.DataFrame({'DOW_Monday': [1], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "\n",
    "if day == 0:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [1], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "elif day == 1:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [1],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "elif day == 2:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [0],'DOW_Wednesday': [1], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "elif day == 3:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [1],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "elif day == 4:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [1], 'DOW_Saturday': [0],'DOW_Sunday': [0]})\n",
    "elif day == 5:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [1],'DOW_Sunday': [0]})\n",
    "else:\n",
    "    df_dummies_DOW = pd.DataFrame({'DOW_Monday': [0], 'DOW_Tuesday': [0],'DOW_Wednesday': [0], 'DOW_Thursday': [0],'DOW_Friday': [0], 'DOW_Saturday': [0],'DOW_Sunday': [1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current weather call to database (uses latest timestamp)\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM DarkSky_current_weather ORDER BY timestamp DESC LIMIT 1;', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold current temperature and rain\n",
    "df_weather = pd.DataFrame({'temp': df['temp'], 'precip_intensity': df['precip_intensity']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all our data in one place\n",
    "dfX = pd.concat([df_time, df_dummies_DOW[['DOW_Monday', 'DOW_Tuesday','DOW_Wednesday', 'DOW_Thursday','DOW_Friday', 'DOW_Saturday','DOW_Sunday']],df_weather], axis =1)\n",
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict journey time (first to last stop) given local time and weather\n",
    "print(\"Your journey will take around\", int(round(rfr_.predict(dfX)[0])), \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_stops = 65 # 65 based on leavetimes progress number\n",
    "origin_stop = 10 # generated from user input based on progression number\n",
    "destination_stop = 17\n",
    "number_of_stops_travelled = destination_stop - origin_stop\n",
    "percentage_of_route_travelled = (number_of_stops_travelled/(total_number_of_stops - 1)) * 100\n",
    "print(\"That is %\" + str(percentage_of_route_travelled) + \" of the entire journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = int(round((int(round(rfr_.predict(dfX)[0])) * percentage_of_route_travelled) / 100))\n",
    "print(\"If you wish to travel between stops\", origin_stop, \"and\", destination_stop, \"your journey will take approximately\", total_time, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current weather call to database (uses latest timestamp)\n",
    "\n",
    "df_stops = pd.read_sql_query('SELECT * FROM static_bus_stop_data;', engine)\n",
    "df_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a list of stops serviced by the 46A\n",
    "\n",
    "df_lt = pd.read_sql_query('SELECT * FROM leavetimes_2017 WHERE tripid = 4395906;', engine)\n",
    "df_lt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_stop_data = pd.DataFrame({'stop_id': df_stops['stop_id'], 'full_name': df_stops['full_name'],'lat': df_stops['latitude'], 'long': df_stops['longitude']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'progress': df_lt['progrnumber'], 'stop_id': df_lt['stoppointid']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df_bus_stop_data, temp, on=['stop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merged dataframe contains every stop serviced (id, name and progress number) by the 46A ordered by progression number\n",
    "merged = merged.drop_duplicates(keep='first')\n",
    "merged = merged.sort_values(['progress'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_stop = input(\"Enter origin stop: \")\n",
    "destination_stop = input(\"Enter destination stop: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('46A_stops_data.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "day_ = dt.datetime.today().weekday() # current day of the week 0=Monday\n",
    "hour_ = (dt.datetime.now().hour)  # current hour \n",
    "\n",
    "print(day_,hour_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    \n",
    "    day_ += 1\n",
    "    day_ = day_ % 7\n",
    "    before = hour_ -1\n",
    "    now = hour_\n",
    "    after = hour_ +1\n",
    "    print(\"The day is\",day_,\"and the hour is\",now,before,after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
