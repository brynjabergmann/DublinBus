{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.loads(f.read())\n",
    "    \n",
    "    host = credentials[\"host\"]\n",
    "    user = credentials[\"db_user\"]\n",
    "    password = credentials[\"db_pass\"]\n",
    "    db = credentials[\"db_name\"]\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:3306/{db}\")\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM trips_2017 WHERE lineid = \"46A\" AND direction = 1', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace missing actual time departure values with timetable values\n",
    "df.actualtime_dep.fillna(df.plannedtime_dep, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values for actual time arrival as we cannot safely assume these are as per timetable\n",
    "df = df[pd.notnull(df['actualtime_arr'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for trip duration\n",
    "df['trip_duration'] = df['actualtime_arr'] - df['actualtime_dep']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the hour of the day the trip took place\n",
    "df['actualtime_dep_H'] = round(df['actualtime_dep']/3600)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of actual time arrival\n",
    "df['actualtime_arr_H'] = round(df['actualtime_arr']/3600)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average hour of the day of the journey\n",
    "df['avg_H'] = (df['actualtime_dep_H'] + df['actualtime_arr_H']) / 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_H'] = df['avg_H'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating column solely for the dates to correlate with the dates column on the historical weather data table\n",
    "df['time'] = df['timestamp'] + df['avg_H'] * 3600\n",
    "df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing suppressed rows where suppressed=1.0\n",
    "df = df.query('suppressed != 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns from timestamp for further processing\n",
    "df['dayofweek'] = df['timestamp']\n",
    "df['monthofyear'] = df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the unix time to datetime format\n",
    "df.dayofweek = pd.to_datetime(df['dayofweek'], unit='s')\n",
    "df.monthofyear = pd.to_datetime(df['monthofyear'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datetime to name of weekday, and to name of month (in separate columns)\n",
    "df['dayofweek'] = df['dayofweek'].dt.weekday_name\n",
    "df['monthofyear'] = df['monthofyear'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for weekday names and name of month\n",
    "df_dayofweek_dummies = pd.get_dummies(df['dayofweek'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows not in the month of March\n",
    "df = df.query('monthofyear == 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df, df_dayofweek_dummies], axis=1, join_axes=[df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull weather data from database\n",
    "df2 = pd.read_sql_query('SELECT * FROM DarkSky_historical_weather_data WHERE year = 2017', engine)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'clear-day':'clear','clear-night':'clear','partly-cloudy-day':'partly-cloudy','partly-cloudy-night':'partly-cloudy'}\n",
    "df2 = df2.replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'day_of_week': 'dayofweek', 'month': 'monthofyear'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['avg_H', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'temp', 'precip_intensity','trip_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip duration is in seconds, convert to minutes and round to the nearest integer\n",
    "df3['trip_duration'] = round(df3['trip_duration']/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['trip_duration'] = df3['trip_duration'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['temp'] = round(df3['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['temp'] = df3['temp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = df3[['avg_H', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'temp','trip_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "You can see that our dataset has eleven columns. The task is to predict the trip duration (last column) based on the day of the week, the time of the day and the weather conditions (temperature and rain intesity). The next step is to split our dataset into attributes and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data from first four columns to X variable\n",
    "X = df3.iloc[:, 0:10]\n",
    "\n",
    "# Assign data from fifth column to y variable\n",
    "y = df3['trip_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset 70/30\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression \n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators : int (default=100)\n",
    "    #The number of boosting stages to perform. \n",
    "    #Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "\n",
    "#max_depth : integer, optional (default=3)\n",
    "    #maximum depth of the individual regression estimators. \n",
    "    #The maximum depth limits the number of nodes in the tree. \n",
    "    #Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "    \n",
    "#min_samples_split : int, float, optional (default=2)\n",
    "    #The minimum number of samples required to split an internal node:\n",
    "    #If int, then consider min_samples_split as the minimum number.\n",
    "    #If float, then min_samples_split is a percentage and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
    "        #Changed in version 0.18: Added float values for percentages.\n",
    "\n",
    "#learning_rate : float, optional (default=0.1)\n",
    "    #learning rate shrinks the contribution of each tree by learning_rate. \n",
    "    #There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "#loss : {‘deviance’, ‘exponential’}, optional (default=’deviance’)\n",
    "    #loss function to be optimized. \n",
    "    #‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. \n",
    "    #For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "params = {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.02, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the importance of each feature based on the model\n",
    "pd.DataFrame({'feature': X.columns, 'importance': clf.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training deviance\n",
    "\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(clf.staged_predict(X_test)):\n",
    "    test_score[i] = clf.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, clf.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(clf.predict([[9, 0, 1, 0, 0, 0, 0, 0, 12, 0.0]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(pred)\n",
    "predictions.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions['estimated_time'] = round(predictions['estimated_time'])\n",
    "predictions['estimated_time'] = predictions['estimated_time'].astype(int)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test,predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regression\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "weights : str or callable\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "\n",
    "    ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "    ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have  a greater influence than neighbors which are further away.\n",
    "    [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "    Uniform weights are used by default.\n",
    "\n",
    "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "    ‘ball_tree’ will use BallTree\n",
    "    ‘kd_tree’ will use KDTree\n",
    "    ‘brute’ will use a brute-force search.\n",
    "    ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, weights = \"uniform\", algorithm = \"auto\")\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(knn.predict([[9, 0, 1, 0, 0, 0, 0, 0, 12, 0.0]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = pd.DataFrame(pred2)\n",
    "predictions2.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions2['estimated_time'] = round(predictions2['estimated_time'])\n",
    "predictions2['estimated_time'] = predictions2['estimated_time'].astype(int)\n",
    "predictions2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 9.4 with 2 neighbours\n",
    "# around 8.6 with 5 neighbours\n",
    "# around 8.4 with 5 neightbours and uniform distance\n",
    "print(metrics.mean_absolute_error(y_test,predictions2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100, max_depth=3, random_state=0)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(regr.predict([[9, 0, 1, 0, 0, 0, 0, 0, 12, 0.0]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = pd.DataFrame(pred3)\n",
    "predictions3.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions3['estimated_time'] = round(predictions3['estimated_time'])\n",
    "predictions3['estimated_time'] = predictions3['estimated_time'].astype(int)\n",
    "predictions3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test,predictions3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR with XGBoost\n",
    "https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "boost = XGBRegressor()\n",
    "boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(round(boost.predict([[9, 0, 1, 0, 0, 0, 0, 0, 12, 0.0]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions6 = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test,predictions6)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NN model\n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=2000)  \n",
    "mlp.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(mlp.predict([[-1.35814288, -0.42520414,  2.35526298, -0.46323037, -0.46323037,\n",
    "       -0.42270958, -0.3360006 , -0.31017723, -1.88838929, -0.29194067]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = pd.DataFrame(pred4)\n",
    "predictions4.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions4['estimated_time'] = round(predictions4['estimated_time'])\n",
    "predictions4['estimated_time'] = predictions4['estimated_time'].astype(int)\n",
    "predictions4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test,predictions4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NN model\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "nnc = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=2000)  \n",
    "nnc.fit(X_train, y_train.values.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 9 am on a Tuesday with 0.0 rain and 12 degrees\n",
    "print(round(nnc.predict([[-1.35814288, -0.42520414,  2.35526298, -0.46323037, -0.46323037,\n",
    "       -0.42270958, -0.3360006 , -0.31017723, -1.88838929, -0.29194067]])[0]),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = nnc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5 = pd.DataFrame(pred5)\n",
    "predictions5.rename(columns={0:'estimated_time'}, inplace=True )\n",
    "predictions5['estimated_time'] = round(predictions5['estimated_time'])\n",
    "predictions5['estimated_time'] = predictions5['estimated_time'].astype(int)\n",
    "predictions5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test,predictions5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBR\n",
    "print(metrics.mean_absolute_error(y_test,predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN - R\n",
    "print(metrics.mean_absolute_error(y_test,predictions4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFR\n",
    "print(metrics.mean_absolute_error(y_test,predictions3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "print(metrics.mean_absolute_error(y_test,predictions2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN - C\n",
    "print(metrics.mean_absolute_error(y_test,predictions5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "print(metrics.mean_absolute_error(y_test,predictions6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_time takes: hour[0], day of week[1:8], temp[8], rain[9]\n",
    "test_time = [[9, 0, 0, 0, 1, 0, 0, 0, 7, 0.0]]\n",
    "test_time_nn = [[-1.35814288, -0.42520414,  2.35526298, -0.46323037, -0.46323037, -0.42270958, -0.3360006 , -0.31017723, -1.88838929, -0.29194067]]\n",
    "# Please, note, test_time_nn is not necessarily the same data as test_time\n",
    "\n",
    "print(\"%.2f\" % clf.predict(test_time)[0],\"minutes\") #GBR\n",
    "print(\"%.2f\" % mlp.predict(test_time_nn)[0],\"minutes\") #ANN - R\n",
    "print(\"%.2f\" % regr.predict(test_time)[0],\"minutes\") # RFR\n",
    "print(\"%.2f\" % knn.predict(test_time)[0],\"minutes\") #KNN\n",
    "print(\"%.2f\" % nnc.predict(test_time_nn)[0],\"minutes\") #ANN - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3[2364:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
